{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1082,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import packages \n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from matplotlib import pyplot as plt\n",
    "import re\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import word_tokenize\n",
    "import nltk\n",
    "from wordcloud import WordCloud\n",
    "from textblob import TextBlob\n",
    "from nltk.corpus import wordnet\n",
    "import datetime\n",
    "import time\n",
    "#nltk.download('punkt')\n",
    "#nltk.download('averaged_perceptron_tagger')\n",
    "#nltk.download('brown')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1261,
   "metadata": {},
   "outputs": [],
   "source": [
    "# set settings\n",
    "%matplotlib inline\n",
    "plt.style.use('ggplot')\n",
    "pd.set_option('display.max_rows', 100)\n",
    "2\n",
    "# Width of the display in characters. If set to None and pandas will correctly auto-detect the width.\n",
    "pd.set_option('display.max_colwidth', 150)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1331,
   "metadata": {},
   "outputs": [],
   "source": [
    "rc = pd.read_csv(\"simplyrecipes.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1332,
   "metadata": {},
   "outputs": [],
   "source": [
    "# missing values\n",
    "# if dish is missing, discard data\n",
    "rc.dropna(subset=['dish'], inplace=True)\n",
    "# drop column with no ingredients\n",
    "rc.dropna(subset=['ingredients'], inplace=True)\n",
    "# if cook time missing, discard data\n",
    "#rc = rc[rc[['time_cook', 'time_prep']].notna().any(axis = 1)]\n",
    "rc.dropna(subset=['time_cook'], inplace=True)\n",
    "rc.dropna(subset=['time_prep'], inplace=True)\n",
    "# drop num_comment column, all NaN\n",
    "rc = rc.drop(columns = ['num_comment', 'time_other_type','time_other', 'time_other_full'])\n",
    "# drop no tag rows\n",
    "rc.dropna(subset = ['tags'], inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1333,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split cell content string to list\n",
    "lst1 = ['time_cook', 'time_prep', 'tags']\n",
    "rc[lst1] = rc[lst1].apply(lambda x: x.str.split(','))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1334,
   "metadata": {},
   "outputs": [],
   "source": [
    "# change rating star to numbers\n",
    "rc.rating_star.unique() # only 5 starts\n",
    "rc['rating_star'] = rc.rating_star.str.replace('yyyyy', '5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1335,
   "metadata": {},
   "outputs": [],
   "source": [
    "# clean ingredients with regex\n",
    "# lower case all letters\n",
    "rc['inglst'] = rc.ingredients.str.lower()\n",
    "# get rid of number & punctuation \n",
    "rc['inglst'] = rc.inglst.apply(lambda x: re.sub('\\W', \" \", x))\n",
    "rc['inglst'] = rc.inglst.apply(lambda x: re.sub('\\d', \" \", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1336,
   "metadata": {},
   "outputs": [],
   "source": [
    "# remove common seasoning\n",
    "lst4 = [\"olive oil\", \"sea salt\", \"black pepper\"]\n",
    "rc['inglst'] = rc.inglst.apply(lambda x: re.sub(\"olive oil\", \"\", x))\n",
    "rc['inglst'] = rc.inglst.apply(lambda x: re.sub(\"sea salt\", \"\", x))\n",
    "rc['inglst'] = rc.inglst.apply(lambda x: re.sub(\"black pepper\", \"\", x))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1337,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tokenize ingredients\n",
    "def safe_word_tokenize(x):\n",
    "    try:\n",
    "        return word_tokenize(x)\n",
    "    except:\n",
    "        return 'empty'\n",
    "#rc['inglst'] = rc.ingredients.apply(safe_word_tokenize)\n",
    "rc['inglst'] = rc.inglst.apply(word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1349,
   "metadata": {},
   "outputs": [],
   "source": [
    "# customize stop words list\n",
    "lst2 = ['pinch','approx','inch','inches','cups','cup','ml','tablespoons','tablespoon','tbsp', 'teaspoon','kg','g','grams','gram','lbs','lb','pound','pounds','ounce','ounces','oz']\n",
    "lst3 = ['salt', 'oil', 'virgin', 'slices']\n",
    "stopIng = stopwords.words('english')\n",
    "stopIng.extend(lst2)\n",
    "stopIng.extend(lst3)\n",
    "#print(stopIng)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1350,
   "metadata": {},
   "outputs": [],
   "source": [
    "# exlude stop words from inglst\n",
    "rc['inglst'] = rc.inglst.apply(lambda x: [el for el in x if el not in stopIng])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1351,
   "metadata": {},
   "outputs": [],
   "source": [
    "# only keep nouns in inglst\n",
    "rc['inglst'] = rc.inglst.apply(nltk.pos_tag)\n",
    "def only_noun(lst):\n",
    "    nouns = [word for (word, pos) in lst if pos[:2]==\"NN\"]\n",
    "    return nouns\n",
    "rc['inglst'] = rc.inglst.apply(only_noun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1341,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse time\n",
    "def unify_time(lst):\n",
    "    time = dict()\n",
    "    for item in lst:\n",
    "        item = item.lstrip()\n",
    "        if 'hour' in item:\n",
    "            hour = int(re.sub('\\D', '', item))\n",
    "            time.update({'hour':hour})\n",
    "\n",
    "        if 'minute' in item:\n",
    "            minute = int(re.sub('\\D', '', item))\n",
    "            time.update({'minute':minute})\n",
    "\n",
    "    duration = time.get('hour', 0)*60 + time.get('minute', 0)\n",
    "    return duration\n",
    "rc['time_cook'] = rc.time_cook.apply(unify_time)\n",
    "rc['time_prep'] = rc.time_prep.apply(unify_time)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1342,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse tag\n",
    "rc['tags'] = rc.tags.apply(lambda x: [el.lower() for el in x ])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1352,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0                                                                                                              [florets, version, parsley, sage, leaves]\n",
       "2                                                           [kale, center, ground, cremini, mushrooms, onion, bread, cut, slices, milk, cheddar, cheese]\n",
       "3                      [butter, water, butter, cut, grill, medium, zucchini, thick, slices, medium, summer, squash, thick, slices, tomatoes, vegetables]\n",
       "5                                       [cauliflower, size, pieces, teaspoons, corn, tortillas, teaspoons, teaspoons, chives, avocado, parsley, garnish]\n",
       "6                                                        [skinless, breast, cut, onion, curry, powder, water, prep, apple, preference, cilantro, onions]\n",
       "                                                                             ...                                                                        \n",
       "930                                                   [boneless, skinless, breast, halves, cutlets, stock, wine, sauvignon, blanc, lemon, juice, capers]\n",
       "931                                                           [beef, shoulder, boneless, look, results, taste, onions, onion, cloves, carrots, segments]\n",
       "932    [butter, plain, pepper, elbow, macaroni, pasta, cavatappi, butter, cream, cheese, brick, cheddar, cheddar, milk, mustard, powder, powder, chives]\n",
       "933                                                                                                          [juice, pepper, onion, celery, sage, thyme]\n",
       "934                     [breadcrumbs, medium, pasta, penne, medium, shells, package, hearts, time, spinach, teaspoons, juice, ricotta, parsley, garnish]\n",
       "Name: inglst, Length: 771, dtype: object"
      ]
     },
     "execution_count": 1352,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# word cloud for inglst\n",
    "rc.inglst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1018,
   "metadata": {},
   "outputs": [],
   "source": [
    "# food = wordnet.synset('food.n.02')\n",
    "# for i in food.closure(lambda s:s.hyponyms()):\n",
    "#     print(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 551,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test why wordtokenize did not work on column ingredients\n",
    "# def safe_word_tokenize( x ):\n",
    "#     try:\n",
    "#         return word_tokenize( x )\n",
    "#     except Exception as e:\n",
    "#         print( f\"Error with {x}. Exception given: {e}\" )\n",
    "#         print( \"-\"*25 + \"\\n\" )\n",
    "# rc.ingredients.apply(safe_word_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {},
   "outputs": [],
   "source": [
    "# extract time\n",
    "#rc['time_cook'].apply(lambda x: x.split(','))\n",
    "# rc['time_cook'] = rc['time_cook'].str.split(',')\n",
    "# rc['time_prep'] = rc['time_prep'].str.split(',')\n",
    "# rc['ingredients'] = rc.ingredients.str.split(',')\n",
    "# rc['tags'] = rc.tags.str.split(',')\n",
    "#rc.rating_star.str.replace('yyyyy', 5)\n",
    "#rc.rating_star.str.replace('yyyyy', '5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1259,
   "metadata": {},
   "outputs": [],
   "source": [
    "# old wrong codes\n",
    "#rc['inglst'].apply(lambda x: x if x not in stopIng else '')\n",
    "#rc.inglist.apply(lambda x: re.sub(lambda y: y, lst4), \"\", x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# need work code\n",
    "# def remove_season(lst,x):\n",
    "#     for item in lst:\n",
    "#         re.sub(item, \"\", x)\n",
    "# rc.inglst.apply(remove_season, lst4)\n",
    "# blob = TextBlob(\" \".join(rc.inglst.iloc[1]))\n",
    "# print(blob.noun_phrases)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#df = pd.read_csv('https://s3.amazonaws.com/nycdsabt01/movie_metadata.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# IDEAS\n",
    "#rc.ingredients.sample(5)\n",
    "# only take the last two words of each , separated words in ingredients\n",
    "#rc.sample(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# reference code\n",
    "#rc.inglst.apply( lambda x: [el for el in x if (el not in stopIng)] )\n",
    "\n",
    "# lines = 'lines is some string of words'\n",
    "# tokenized = nltk.word_tokenize(lines)\n",
    "# nouns = [word for (word, pos) in nltk.pos_tag(tokenized) if(pos[:2] == 'NN')]\n",
    "# nouns = [(word, pos) for (word, pos) in nltk.pos_tag(tokenized)]\n",
    "# nltk.pos_tag(tokenized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# parse tags\n",
    "# test = rc.tags.apply(lambda x: [el for el in x if el == 'beef'])\n",
    "# def sort_tag(lst):\n",
    "#     for tag in lst:\n",
    "#         switch(tag:\n",
    "#                beef = 'beef', chicken = 'chicken', vege = 'vegetarian', seafood = 'fish and seafood', pork = pork)\n",
    "#     return main\n",
    "# rc.tags.apply(sort_tag)\n",
    "#rc.inglst.apply( lambda x: [el for el in x if (el not in stopIng)] )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
